
\section{Application Flow}
\label{sec:flow}

The main application flow consists of first reading the config file. \gls{fids} used the default config path if not overwritten by passing the attribute. Then it starts the scanner if appropriate. After that, it starts the investigator if required. If any of the two configurations do not exist, the \gls{fids} does not execute the respective component. If both are missing, it does neither scan nor investigate.

By passing the timeline flag, the \gls{hids}-flow gets ignored. Instead, the \gls{fids} creates the timeline and finishes the run.

\subsection{Scanner}
\label{sec:Scanner}

The scanner component is the first component of the \gls{hids} path. It is responsible for getting all the information from the \gls{fs} for the configured paths. It has multiple stages.

\begin{enumerate}
    \item Initialization
    \item Scan
    \item Error Logging
    \item Storing
    \item Error Logging
    \item Finalizing
\end{enumerate}

In the initialization phase, the scanner creates a run object. The scanner immediately saves the run to the database. This way, users know just by looking at the database if there are any yet incompleted runs. This data also creates the first opportunity to look for inconsistencies. If there are a lot of started runs, something suspicious might be going on. It also creates the hash of the configuration and already saves it to the database.

The scan phase has more steps to it. First it creates the \gls{pytsk} object called `img\_info'. \Gls{pytsk} returns that when it receives the path to the disk image. Then the important `fs\_info' object is created by passing the img\_info object. This way, the scanner has access to the \gls{fs}. The scan starts by calling `open\_directory\_rec' for each scan path. This function keeps track of all directories it already traversed into as to avoid circular loops and unnecessary steps. Then it checks if the path is in the ignored paths. It then iterates over all objects in the directory.

For all entries, it then checks if it is a valid entry with the required attributes to continue. Afterward, it checks if it is a directory. For all directories, the function first checks if it already visited the directory and if not it calls itself with the new directory as the parameter. If the entry is a file, it is parsed into a python object and then stored into a local list of found files. It also saves any errors that occur by creating an error object and storing them in a list of errors.

In the error logging phase, the scanner stores all errors that have occurred in the scan process to the database by iterating over them and saving one by one. Even if the scanner crashes when storing the files for some reason, it already persisted the errors.

The file saving phase occurs after the first error logging phase. Here the files are saved like the errors by iterating over them and saving one by one. Should any additional error occur while saving the files, the scanner adds them to a new list of errors. 

There is a second error logging phase. In this phase, the errors that occurred while saving the files get stored into the database. The functionality is the same as for the first error logging phase.

In the finalizing phase, the run object gets updated, and the end timestamp added. It is then updated on the database. At this point, the scanner finished. It has written all the appropriate files from the \gls{fs} and all errors that occurred to the database. The run object on the database has a fitting start and end timestamp. 


\subsection{Investigator}
\label{sec:Investigator}

The investigator component is responsible for finding \glspl{intrusion}. As discussed in section \ref{sec:conf:investigator} it does so with predefined rules and investigations. To explain how the investigator works, I split it into different steps as with the scanner.

\begin{enumerate}
    \item Parsing configuration
    \item Fetching runs
    \item Fetching files
    \item Investigation
    \item Report generation
\end{enumerate}

First, the investigator needs to parse the configuration. The investigator configuration is more intricate than the other configurations. Because of that, parsing needs more steps. The \gls{fids} first flattens the alerts by expanding the `greater' and `equals' list appropriately to the sub-rules. Afterward, it expands the investigations by adding the configuration from the alerts directly to the investigations. This way, it is easier to access them in the following steps. The lists are continuously updated not to contain duplicates.

The investigator then fetches all run \gls{id} and selects the correct ones by finding the most recent finished runs. If the `validation\_run' property is set, it takes that one as the reference instead of the second most recent one. The investigator always takes the most recent for validation.

After the runs are acquired, the investigator retrieves the files by executing the \gls{sql} query shown in listing \ref{lst:file:query}, which joins the file table with itself on the inode address or path and name. This way, the investigator can make good use of the indices that exist on this table. After the files get fetched, they are parsed and put into a list of tuples. This process takes some time for a large number of files. 

\begin{lstlisting}[language=sql, numbers=left, caption=SQL Querry for files, label=lst:file:query]
SELECT * FROM FIDS_FILE first 
    LEFT JOIN FIDS_FILE second 
        on (first.meta_addr=second.meta_addr or 
            first.path=second.path and 
            first.name_name=second.name_name)
    WHERE first.run_id = ? and second.run_id=? 
        or second.run_id is null;
\end{lstlisting}

After that, the investigator starts the comparison. It first checks the configuration hashes of the two runs. Then it goes through each file and checks if it needs checking in any investigation by validating the path and \gls{regex} whitelist. Then, it validates if the file has been renamed, created or deleted. It then checks the blacklist for a match.  Next, it checks all the `equal' and `greater' attributes. For each check, it creates a detection error if necessary. 

Ultimately, the alerts are used to generate a report. It then prints that report to the standard output and is meant to be used for further processing. 

\subsection{Timeline creator}
\label{sec:Timeliner}

The timeline creator part is quite straightforward. It first retrieves all the data for all files from the database. It then goes through each and prints a list in the time machine format. This way, the output of the timeline creator can be used by many tools like the `mactime' utility, which parses the input automatically and creates an ASCII timeline. The only special part is the retrieval of the files. Instead of storing them in a list, the system stores them in a set. This way duplicated files with the same attributes are not considered twice. The set uses a \gls{nonhash} for duplication detection.
